{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\cupy\\_environment.py:205: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data folder is set to `c:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\neuspell\\../data` script\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import contextualSpellCheck\n",
    "import neuspell\n",
    "from neuspell import BertChecker\n",
    "from neuspell import SclstmChecker\n",
    "import spellchecker\n",
    "import enchant\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import nltk\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some initial Pre-processing (Not Important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_address = pd.read_csv('Dataset/list_of_real_usa_addresses.csv')\n",
    "real_address = pd.read_csv('uscities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = []\n",
    "state = []\n",
    "city_state_check = []\n",
    "for add in check_address['city']:\n",
    "    city.append(add)\n",
    "\n",
    "for address in check_address['state']:\n",
    "    state.append(address)\n",
    "\n",
    "for something in range(0,len(check_address['city'])):\n",
    "    city_state_check.append(city[something] + ',' + state[something])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = []\n",
    "state = []\n",
    "city_state_real = []\n",
    "for add in real_address['city']:\n",
    "    city.append(add)\n",
    "\n",
    "for address in real_address['state_id']:\n",
    "    state.append(address)\n",
    "\n",
    "for something in range(0, len(real_address['city'])):\n",
    "    city_state_real.append(city[something] + ',' + state[something])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_state_check\n",
    "print(city_state_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_addresses = pd.read_excel('usa_address.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_addresses['city_state']= city_state_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           New York,NY\n",
       "1        Los Angeles,CA\n",
       "2            Chicago,IL\n",
       "3              Miami,FL\n",
       "4             Dallas,TX\n",
       "              ...      \n",
       "28333          Gross,NE\n",
       "28334         Lotsee,OK\n",
       "28335      The Ranch,MN\n",
       "28336       Shamrock,OK\n",
       "28337         Monowi,NE\n",
       "Name: city_state, Length: 28338, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_addresses['city_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>city</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_id</th>\n",
       "      <th>city_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York,NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles,CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago,IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Miami</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>Miami,FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas,TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28333</th>\n",
       "      <td>28333</td>\n",
       "      <td>Gross</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>NE</td>\n",
       "      <td>Gross,NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28334</th>\n",
       "      <td>28334</td>\n",
       "      <td>Lotsee</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>OK</td>\n",
       "      <td>Lotsee,OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28335</th>\n",
       "      <td>28335</td>\n",
       "      <td>The Ranch</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>The Ranch,MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28336</th>\n",
       "      <td>28336</td>\n",
       "      <td>Shamrock</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>OK</td>\n",
       "      <td>Shamrock,OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28337</th>\n",
       "      <td>28337</td>\n",
       "      <td>Monowi</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>NE</td>\n",
       "      <td>Monowi,NE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28338 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         city  state_name state_id      city_state\n",
       "0               0     New York    New York       NY     New York,NY\n",
       "1               1  Los Angeles  California       CA  Los Angeles,CA\n",
       "2               2      Chicago    Illinois       IL      Chicago,IL\n",
       "3               3        Miami     Florida       FL        Miami,FL\n",
       "4               4       Dallas       Texas       TX       Dallas,TX\n",
       "...           ...          ...         ...      ...             ...\n",
       "28333       28333        Gross    Nebraska       NE        Gross,NE\n",
       "28334       28334       Lotsee    Oklahoma       OK       Lotsee,OK\n",
       "28335       28335    The Ranch   Minnesota       MN    The Ranch,MN\n",
       "28336       28336     Shamrock    Oklahoma       OK     Shamrock,OK\n",
       "28337       28337       Monowi    Nebraska       NE       Monowi,NE\n",
       "\n",
       "[28338 rows x 5 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_addresses.to_excel('usa_addresses.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_address.columns\n",
    "usa_addresses = real_address[['city', 'state_name', 'state_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_addresses.to_excel('usa_address.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address Correction (Leveshtein Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('Dataset/list_of_real_usa_addresses.csv')\n",
    "predefined_dataset = pd.read_excel('usa_address.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing with Cities and States together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_state_sample=[]\n",
    "for city in range(0,len(sample)):\n",
    "    sample_city = sample['city'][city]\n",
    "    sample_state = sample['state'][city]\n",
    "\n",
    "    string_output = str(sample_city)+','+str(sample_state)\n",
    "    city_state_sample.append(string_output)\n",
    "\n",
    "city_state_predefined = predefined_dataset['city_state']\n",
    "city_state_predefined = list(city_state_predefined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length - 85\n"
     ]
    }
   ],
   "source": [
    "not_present_city_state = []\n",
    "\n",
    "for city in city_state_sample:\n",
    "    if city not in city_state_predefined:\n",
    "        not_present_city_state.append(city)\n",
    "print(f\"Length - {len(not_present_city_state)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing with City and State different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cities = []\n",
    "sample_city = sample['city']\n",
    "sample_city = list(sample_city)\n",
    "\n",
    "predefined_city = predefined_dataset['city']\n",
    "predefined_city = list(predefined_city)\n",
    "\n",
    "for city in sample_city:\n",
    "    if city not in predefined_city:\n",
    "        sample_cities.append(city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_states = []\n",
    "\n",
    "sample_state = sample['state']\n",
    "sample_state = list(sample_state)\n",
    "\n",
    "predefined_state = predefined_dataset['state_id']\n",
    "predefined_state = list(predefined_state)\n",
    "\n",
    "for state in sample_state:\n",
    "    if state not in predefined_state:\n",
    "        sample_states.append(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_present_city_state = []\n",
    "\n",
    "for city in range(0,len(sample_city)):\n",
    "\n",
    "    if sample_city[city] in sample_cities:\n",
    "        string1 = sample_city[city]+','+sample_state[city]\n",
    "        not_present_city_state.append(string1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in range(0,len(sample_state)):\n",
    "    \n",
    "    if sample_state[state] in sample_states:\n",
    "        string1 = sample_city[state]+','+sample_state[state]\n",
    "        not_present_city_state.append(string1)\n",
    "\n",
    "not_present_city_state = set(not_present_city_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_corrected = {}\n",
    "minimum = 999\n",
    "for iterator_city_state in not_present_city_state:\n",
    "    minimum = 999\n",
    "    for correct_city_state in city_state_predefined:\n",
    "        temp = enchant.utils.levenshtein( iterator_city_state, correct_city_state)\n",
    "        if temp < 5:\n",
    "            if temp < minimum:\n",
    "                minimum = temp\n",
    "                cities_corrected[iterator_city_state] = correct_city_state\n",
    "\n",
    "        else:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Albany,N': 'Albany,NY',\n",
       " 'Bellinghm,MN': 'Bellingham,MN',\n",
       " 'Ware,MA': 'Wade,MS',\n",
       " 'Wareham,MA': 'Waltham,MA',\n",
       " 'Northhampton,MA': 'Northampton,MA',\n",
       " 'Abington,MA': 'Abingdon,VA',\n",
       " 'Norh Adms,MA': 'North Adams,MA',\n",
       " 'East Falmth,MA': 'East Falmouth,MA',\n",
       " 'Salem,A': 'Salem,MA'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_corrected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Method:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check_cities = check_address['city'] \n",
    "check_state = check_address['state']\n",
    "official_cities = list(usa_addresses['city'])\n",
    "official_state_id = list(usa_addresses['state_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_function(embeddings1, embeddings2):  # Cosine Function\n",
    "\n",
    "    A = embeddings1\n",
    "    B = embeddings2\n",
    "    cosine = np.dot(A, B)/(norm(A)*norm(B))\n",
    "    return cosine\n",
    "\n",
    "\n",
    "model_path = 'local/path/to/model'  # Loading the model\n",
    "model = SentenceTransformer(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_state = []\n",
    "for city in range(0,len(check_cities)):\n",
    "    if check_cities[city] not in official_cities:\n",
    "        string1 = check_cities[city] + ',' + check_state[city]\n",
    "        city_state.append(string1)\n",
    "\n",
    "    elif check_state[city] not in official_state_id:\n",
    "        string2 = check_state[city] + ',' +check_state[city]\n",
    "        city_state.append(string2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abington,MA',\n",
       " 'Bellinghm,MN',\n",
       " 'Chelmsford,MA',\n",
       " 'East Falmth,MA',\n",
       " 'Leicester,MA',\n",
       " 'Methuen,MA',\n",
       " 'Norh Adms,MA',\n",
       " 'North Attleboro,MA',\n",
       " 'North Dartmouth,MA',\n",
       " 'North Oxford,MA',\n",
       " 'North Reading,MA',\n",
       " 'Northborough,MA',\n",
       " 'Northhampton,MA',\n",
       " 'A,A',\n",
       " 'Seekonk,MA',\n",
       " 'Sturbridge,MA',\n",
       " 'Tewksbury,MA',\n",
       " 'Walpole,MA',\n",
       " 'Ware,MA',\n",
       " 'Wareham,MA',\n",
       " 'N,N',\n",
       " 'Camillus,NY',\n",
       " 'Canandaigua,NY',\n",
       " 'Catskill,NY',\n",
       " 'Cheektowaga,NY',\n",
       " 'Cobleskill,NY',\n",
       " 'Cortlandville,NY',\n",
       " 'East Greenbush,NY',\n",
       " 'Fishkill,NY',\n",
       " 'Greece,NY',\n",
       " 'Halfmoon,NY',\n",
       " 'Herkimer,NY',\n",
       " 'Horseheads,NY',\n",
       " 'Lowville,NY',\n",
       " 'Macedon,NY',\n",
       " 'Mohegan Lake,NY',\n",
       " 'East Windsor,CT',\n",
       " 'Old Saybrook,CT',\n",
       " 'Southington,CT']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(city_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'Abington, MA'\n",
    "correct_city = 'New York, NY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode1 = model.encode([city])[0]\n",
    "encode2 = model.encode([correct_city])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(encode1, encode2):\n",
    "    \n",
    "    np.asarray(encode1, e)\n",
    "    intersection = np.logical_and( encode1, encode2)\n",
    "    # print(intersection)\n",
    "    union = np.logical_or(encode1, encode2 )\n",
    "\n",
    "    return intersection.sum()/float(union.sum())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_percentage = cosine_function( encode1, encode2)\n",
    "# similarity_percentage = jaccard_similarity(encode1, encode2)\n",
    "# print(encode1)\n",
    "# print(similarity_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abington,MA\n",
      "Bellinghm,MN\n",
      "In\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cities_corrected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11468/2201416213.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msimilarity_percentage\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mminimum\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mminimum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarity_percentage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mcities_corrected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrect_city\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cities_corrected' is not defined"
     ]
    }
   ],
   "source": [
    "for city in city_state:\n",
    "    print(city)\n",
    "    minimum=0\n",
    "    encode1 = model.encode([city])[0]\n",
    "    for correct_city in city_state_real:\n",
    "        encode2 = model.encode([correct_city])[0]\n",
    "        similarity_percentage = cosine_function( encode1, encode2)\n",
    "        # print(similarity_percentage)\n",
    "        # print(correct_city)\n",
    "        if similarity_percentage>=0.80:\n",
    "            # print(city)\n",
    "            print('In')\n",
    "            if similarity_percentage > minimum:\n",
    "                minimum = similarity_percentage\n",
    "                cities_corrected[city] = correct_city\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in city_state:\n",
    "    if cities_corrected[city]==None:\n",
    "        cities_corrected[city]= 'Nothing Found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abington': 'Abingdon',\n",
       " 'Chelmsford': 'Elmsford',\n",
       " 'Leicester': 'Worcester',\n",
       " 'Methuen': 'Meriden',\n",
       " 'North Attleboro': 'North Attleborough',\n",
       " 'North Dartmouth': 'North Falmouth',\n",
       " 'North Oxford': 'Port Orford',\n",
       " 'North Reading': 'Port Reading',\n",
       " 'Northborough': 'Northboro',\n",
       " 'Northhampton': 'Northampton',\n",
       " 'Seekonk': 'Sedona',\n",
       " 'Sturbridge': 'Stockbridge',\n",
       " 'Tewksbury': 'Lewisburg',\n",
       " 'Walpole': 'Waldorf',\n",
       " 'Ware': 'Ward',\n",
       " 'Wareham': 'Waltham',\n",
       " 'Camillus': 'Camilla',\n",
       " 'Canandaigua': 'Catasauqua',\n",
       " 'Catskill': 'Cresskill',\n",
       " 'Cheektowaga': 'Chetopa',\n",
       " 'Cobleskill': 'Noblesville',\n",
       " 'Cortlandville': 'Collinsville',\n",
       " 'East Greenbush': 'East Greenville',\n",
       " 'Fishkill': 'Highfill',\n",
       " 'Greece': 'Greene',\n",
       " 'Halfmoon': 'Half Moon',\n",
       " 'Herkimer': 'Herriman',\n",
       " 'Horseheads': 'Morehead',\n",
       " 'Lowville': 'Lionville',\n",
       " 'Macedon': 'Macon',\n",
       " 'Mohegan Lake': 'Moses Lake',\n",
       " 'East Windsor': 'East Bangor',\n",
       " 'Old Saybrook': 'Saybrook',\n",
       " 'Southington': 'Worthington'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(not_present_city))\n",
    "print(len(not_present_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Bigram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contextual Spell Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "contextualSpellCheck.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected: Rishil won the Qlondon elections.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Rishil wo the Qlondon elections.')\n",
    "print('Corrected:', doc._.outcome_spellCheck)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Spell Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = BertChecker()\n",
    "checker.from_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rishil to the Qlondon elections .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.correct(\"Rishil wo the Qlondon elections.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bingo\n",
      "{'goingto', 'bingo', 'aingt', 'thingto'}\n",
      "write\n",
      "{'write', 'wre', 'wrote', 'wite'}\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown([\"Abingto\", \"Avenue\", \"study\", \"wrte\"])\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.5\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "a = 'Abington'\n",
    "b = 'Abingdon'\n",
    "\n",
    "seq = difflib.SequenceMatcher(None, a, b)\n",
    "d = seq.ratio()*100\n",
    "print(d)\n",
    "### OUTPUT: 87.323943\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 353/353 [00:00<00:00, 88.2kB/s]\n",
      "Downloading: 100%|██████████| 798k/798k [00:01<00:00, 607kB/s]  \n",
      "Downloading: 100%|██████████| 456k/456k [00:01<00:00, 452kB/s]  \n",
      "Downloading: 100%|██████████| 2.11M/2.11M [00:01<00:00, 1.11MB/s]\n",
      "Downloading: 100%|██████████| 239/239 [00:00<00:00, 238kB/s]\n",
      "Downloading: 100%|██████████| 1.74k/1.74k [00:00<00:00, 1.72MB/s]\n",
      "Downloading: 100%|██████████| 558M/558M [00:36<00:00, 15.3MB/s]   \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"oliverguhr/spelling-correction-english-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"oliverguhr/spelling-correction-english-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Abingt.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fix_spelling = pipeline(\"text2text-generation\",model=\"oliverguhr/spelling-correction-english-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Bellinghem.'}]\n"
     ]
    }
   ],
   "source": [
    "print(fix_spelling(\"Bellinghem\",max_length=2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.25.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "\n",
    "# determining the values of the parameters\n",
    "string1 = \"abc\"\n",
    "string2 = \"aef\"\n",
    "\n",
    "# the Levenshtein distance between\n",
    "# string1 and string2\n",
    "print(enchant.utils.levenshtein(string1, string2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abbreviation (Address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviation = pd.read_excel('Dataset/Abrreviations.xlsx')\n",
    "sample = pd.read_csv('Dataset/list_of_real_usa_addresses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_abbreviations = abbreviation['Abbreviations']\n",
    "proper_abbreviations = list(proper_abbreviations)\n",
    "\n",
    "correct_abbreviations = abbreviation['Corrected_Abbreviations']\n",
    "correct_abbreviations = list(correct_abbreviations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {}\n",
    "for something in range(0,len(proper_abbreviations)):\n",
    "    mapping_dict[proper_abbreviations[something]] = correct_abbreviations[something]\n",
    "    \n",
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_df = pd.DataFrame()\n",
    "corrected_df['1'] = mapping_dict.keys()\n",
    "corrected_df['2'] = mapping_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ave</td>\n",
       "      <td>Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blvd</td>\n",
       "      <td>Boulevard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cyn</td>\n",
       "      <td>Canyon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr</td>\n",
       "      <td>Drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ln</td>\n",
       "      <td>Lane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rd</td>\n",
       "      <td>Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>St</td>\n",
       "      <td>Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N</td>\n",
       "      <td>North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NE</td>\n",
       "      <td>North-East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NW</td>\n",
       "      <td>North-West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SE</td>\n",
       "      <td>South-East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SW</td>\n",
       "      <td>South-West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>W</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hwy</td>\n",
       "      <td>Highway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Av</td>\n",
       "      <td>Avenue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1           2\n",
       "0    Ave      Avenue\n",
       "1   Blvd   Boulevard\n",
       "2    Cyn      Canyon\n",
       "3     Dr       Drive\n",
       "4     Ln        Lane\n",
       "5     Rd        Road\n",
       "6     St      Street\n",
       "7      E        East\n",
       "8      N       North\n",
       "9     NE  North-East\n",
       "10    NW  North-West\n",
       "11     S       South\n",
       "12    SE  South-East\n",
       "13    SW  South-West\n",
       "14     W        West\n",
       "15   Hwy     Highway\n",
       "16    Av      Avenue"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "Address = sample['address']\n",
    "Address = list(Address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "abbrev = []\n",
    "\n",
    "for part in Address:\n",
    "    nltk_tokens = nltk.word_tokenize(part)\n",
    "    tokens.append(nltk_tokens)\n",
    "\n",
    "for part in tokens:\n",
    "    for some in range(0,len(part)):\n",
    "        if part[some] in mapping_dict.keys():\n",
    "            part[some]= mapping_dict[part[some]]\n",
    "\n",
    "for tok in range(0, len(tokens)):\n",
    "    tokens[tok] = ' '.join(tokens[tok])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "def checkAutoCorrect(tokenlist):\n",
    "    '''This function checks whether words are english or not and corrects the spelling mistakes\n",
    "    Input : list of token\n",
    "    Output : corrected string\n",
    "    '''\n",
    "    temp = ''\n",
    "    spell = SpellChecker(language='en')\n",
    "    for token in tokenlist:\n",
    "        # check for abbreviation\n",
    "        if len(token) <= 3:\n",
    "            temp = temp+\" \"+token\n",
    "        # check if word is english\n",
    "        elif dict.check(token):\n",
    "            temp = temp+\" \"+token\n",
    "        else:\n",
    "            # correct the word if spelling mistakes\n",
    "            correctword = str(spell.correction(token)) if spell.correction(token) else token\n",
    "            temp = temp+\" \"+correctword\n",
    "\n",
    "    original = ' '.join(tokenlist)\n",
    "    print(f'original string:{original} , replaced string:{temp}, ratio: {fuzz.WRatio(original, temp)}')\n",
    "    return temp.upper()\n",
    "\n",
    "if __name__ == \"__main__\"  :\n",
    "    dict = enchant.Dict(\"en_US\")\n",
    "    dataset1 = pd.read_csv(\"test.csv\")\n",
    "    dataset1 = pd.DataFrame(dataset1[\"Provider Name\"], columns=[\"Provider Name\"])\n",
    "    # tokenization of provider name\n",
    "    dataset1[\"tokenized Name\"] = [list(word_tokenize(x)) for x in dataset1[\"Provider Name\"]]\n",
    "    # correction  string\n",
    "    dataset1[\"Filtered Name\"] = [checkAutoCorrect(x) for x in dataset1[\"tokenized Name\"]]\n",
    "    print(dataset1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777 Brockton Avenue\n",
      "30 Memorial Drive\n",
      "250 Hartford Avenue\n",
      "700 Oak Street\n",
      "66-4 Parkhurst Road\n",
      "591 Memorial Drive\n",
      "55 Brooksby Village Way\n",
      "137 Teaticket Highway\n",
      "42 Fairhaven Commons Way\n",
      "374 William South Canning Boulevard\n",
      "121 Worcester Road\n",
      "677 Timpany Boulevard\n",
      "337 Russell Street\n",
      "295 Plymouth Street\n",
      "1775 Washington Street\n",
      "280 Washington Street\n",
      "20 Soojian Drive\n",
      "11 Jungle Road\n",
      "301 Massachusetts Avenue\n",
      "780 Lynnway\n",
      "70 Pleasant Valley Street\n",
      "830 Curran Memorial Highway\n",
      "1470 South Washington Street\n",
      "506 State Road\n",
      "742 Main Street\n",
      "72 Main Street\n",
      "200 Otis Street\n",
      "180 North King Street\n",
      "555 East Main Street\n",
      "555 Hubbard Ave-Suite 12\n",
      "300 Colony Place\n",
      "301 Falls Boulevard\n",
      "36 Paramount Drive\n",
      "450 Highland Avenue\n",
      "1180 Fall River Avenue\n",
      "1105 Boston Road\n",
      "100 Charlton Road\n",
      "262 Swansea Mall Drive\n",
      "333 Main Street\n",
      "550 Providence Highway\n",
      "352 Palmer Road\n",
      "3005 Cranberry Highway Rt 6 28\n",
      "250 Rt 59\n",
      "141 Washington Avenue Extension\n",
      "13858 Rt 31 West\n",
      "2055 Niagara Falls Boulevard\n",
      "101 Sanford Farm Shpg Center\n",
      "297 Grant Avenue\n",
      "4133 Veterans Memorial Drive\n",
      "6265 Brockport Spencerport Road\n",
      "5399 West Genesse Street\n",
      "3191 County rd 10\n",
      "30 Catskill\n",
      "161 Centereach Mall\n",
      "3018 East Avenue\n",
      "100 Thruway Plaza\n",
      "8064 Brewerton Road\n",
      "5033 Transit Road\n",
      "3949 Route 31\n",
      "139 Merchant Place\n",
      "85 Crooked Hill Road\n",
      "872 Route 13\n",
      "279 Troy Road\n",
      "2465 Hempstead Turnpike\n",
      "6438 Basile Rowe\n",
      "25737 US Rt 11\n",
      "901 Route 110\n",
      "2400 Route 9\n",
      "10401 Bennett Road\n",
      "1818 State Route 3\n",
      "4300 Lakeville Road\n",
      "990 Route 5 20\n",
      "311 RT 9W\n",
      "200 Dutch Meadows Lane\n",
      "100 Elm Ridge Center Drive\n",
      "1549 Rt 9\n",
      "5360 Southwestern Boulevard\n",
      "103 North Caroline Street\n",
      "1000 State Route 36\n",
      "1400 County Road 64\n",
      "135 Fairgrounds Memorial Pkwy\n",
      "2 Gannett Drive\n",
      "233 5th Avenue Ext\n",
      "601 Frank Stottile Boulevard\n",
      "350 East Fairmount Avenue\n",
      "4975 Transit Road\n",
      "579 Troy-Schenectady Road\n",
      "5783 So Transit Road\n",
      "7155 State Rt 12 South\n",
      "425 Route 31\n",
      "3222 State Rt 11\n",
      "200 Sunrise Mall\n",
      "43 Stephenville Street\n",
      "750 Middle Country Road\n",
      "470 Route 211 East\n",
      "3133 East Main Street\n",
      "288 Larkin\n",
      "41 Anawana Lake Road\n",
      "4765 Commercial Drive\n",
      "1201 Rt 300\n",
      "255 West Main Street\n",
      "120 Commercial Parkway\n",
      "1400 Farmington Avenue\n",
      "161 Berlin Road\n",
      "67 Newton Road\n",
      "656 New Haven Avenue\n",
      "69 Prospect Hill Road\n",
      "150 Gold Star Highway\n",
      "900 Boston Post Road\n",
      "2300 Dixwell Avenue\n",
      "495 Flatbush Avenue\n",
      "180 River Road\n",
      "420 Buckland Hills Drive\n",
      "1365 Boston Post Road\n",
      "1100 New Haven Road\n",
      "315 Foxon Boulevard\n",
      "164 Danbury Road\n",
      "3164 Berlin Turnpike\n",
      "474 Boston Post Road\n",
      "650 Main Avenue\n",
      "680 Connecticut Avenue\n",
      "220 Salem Turnpike\n",
      "655 Boston Post Road\n",
      "625 School Street\n",
      "80 Town Line Road\n",
      "465 Bridgeport Avenue\n",
      "235 Queen Street\n",
      "150 Barnum Avenue Cutoff\n",
      "970 Torringford Street\n",
      "844 No Colony Road\n",
      "910 Wolcott Street\n",
      "155 Waterford Parkway No\n",
      "515 Sawmill Road\n",
      "2473 Hackworth Road\n",
      "630 Coonial Promenade Pkwy\n",
      "2643 Highway 280 West\n",
      "540 West Bypass\n",
      "5560 Mcclellan Boulevard\n",
      "1450 No Brindlee Mtn Pkwy\n",
      "1011 US Highway 72 East\n",
      "973 Gilbert Ferry Road Se\n",
      "1717 South College Street\n",
      "701 Mcmeans Avenue\n",
      "750 Academy Drive\n",
      "312 Palisades Boulevard\n",
      "1600 Montclair Road\n",
      "5919 Trussville Crossings Pkwy\n",
      "9248 Parkway East\n",
      "1972 Highway 431\n",
      "10675 Highway 5\n",
      "2041 Douglas Avenue\n",
      "5100 Highway 31\n",
      "1916 Center Point Road\n",
      "1950 West Main Street\n",
      "16077 Highway 280\n",
      "1415 7Th Street South\n",
      "626 Olive Street Sw\n",
      "27520 Highway 98\n",
      "2800 Spring Avn South-West\n",
      "969 Us Highway 80 West\n",
      "3300 South Oates Street\n",
      "4310 Montgomery Highway\n",
      "600 Boll Weevil Circle\n",
      "3176 South Eufaula Avenue\n",
      "7100 Aaron Aronov Drive\n",
      "10040 County Road 48\n",
      "3186 Highway 171 North\n",
      "3100 Hough Road\n",
      "2200 South Mckenzie Street\n",
      "2001 Glenn Bldv Sw\n",
      "340 East Meighan Boulevard\n",
      "890 Odum Road\n",
      "1608 West Magnolia Avenue\n",
      "501 Willow Lane\n",
      "170 Fort Morgan Road\n",
      "11697 US Highway 431\n",
      "42417 Highway 195\n",
      "1706 Military Street South\n",
      "1201 Highway 31 North-West\n",
      "209 Lakeshore Parkway\n",
      "2780 John Hawkins Pkwy\n",
      "5335 Highway 280 South\n",
      "1007 Red Farmer Drive\n",
      "2900 South Mem PkwyDrake Avenue\n",
      "11610 Memorial Pkwy South\n",
      "2200 Sparkman Drive\n",
      "330 Sutton Road\n",
      "6140A Univ Drive\n",
      "4206 North College Avenue\n",
      "1625 Pelham South\n",
      "1801 Highway 78 East\n",
      "8551 Whitfield Avenue\n",
      "8650 Madison Boulevard\n",
      "145 Kelley Boulevard\n",
      "1970 South University Boulevard\n",
      "6350 Cottage Hill Road\n",
      "101 South Beltline Highway\n",
      "2500 Dawes Road\n",
      "5245 Rangeline Service Road\n",
      "685 Schillinger Road\n",
      "3371 South Alabama Avenue\n",
      "10710 Chantilly Pkwy\n",
      "3801 Eastern Boulevard\n",
      "6495 Atlanta Highway\n",
      "851 Ann Street\n",
      "15445 Highway 24\n",
      "517 West Avalon Avenue\n",
      "5710 Mcfarland Boulevard\n",
      "2453 2Nd Avenue East\n",
      "2900 Pepperrell Pkwy\n",
      "92 Plaza Lane\n",
      "1537 Highway 231 South\n",
      "2181 Pelham Pkwy\n",
      "165 Vaughan Lane\n",
      "3700 Highway 280-431 North\n",
      "1903 Cobbs Ford Road\n",
      "4180 Us Highway 431\n",
      "13675 Highway 43\n",
      "1095 Industrial Pkwy\n",
      "24833 Johnt Reidprkw\n",
      "1501 Highway 14 East\n",
      "7855 Moffett Road\n",
      "150 Springville Station Boulevard\n",
      "690 Highway 78\n",
      "41301 US Highway 280\n",
      "214 Haynes Street\n",
      "1300 Gilmer Avenue\n",
      "34301 Highway 43\n",
      "1420 Us 231 South\n",
      "1501 Skyland Boulevard East\n",
      "3501 20th Avenue\n",
      "1300 Montgomery Highway\n",
      "4538 Us Highway 231\n",
      "2575 Us Highway 43\n"
     ]
    }
   ],
   "source": [
    "for tok in tokens:\n",
    "    print(tok)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Corrector - (Address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.17.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk>=3.1->textblob) (2021.10.23)\n",
      "Requirement already satisfied: colorama in c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm->nltk>=3.1->textblob) (0.4.3)\n",
      "Collecting jamspell\n",
      "  Using cached jamspell-0.0.12.tar.gz (174 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: jamspell\n",
      "  Building wheel for jamspell (setup.py): started\n",
      "  Building wheel for jamspell (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for jamspell\n",
      "Failed to build jamspell\n",
      "Installing collected packages: jamspell\n",
      "    Running setup.py install for jamspell: started\n",
      "    Running setup.py install for jamspell: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\gaura\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2as2bd9y\\\\jamspell_65f5512d22764ac8a97b2a21f389daae\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\gaura\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2as2bd9y\\\\jamspell_65f5512d22764ac8a97b2a21f389daae\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-wheel-moui73_o'\n",
      "       cwd: C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-install-2as2bd9y\\jamspell_65f5512d22764ac8a97b2a21f389daae\\\n",
      "  Complete output (45 lines):\n",
      "  C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\dist.py:732: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building '_jamspell' extension\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-install-2as2bd9y\\jamspell_65f5512d22764ac8a97b2a21f389daae\\setup.py\", line 55, in <module>\n",
      "      setup(\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\__init__.py\", line 155, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 148, in setup\n",
      "      return run_commands(dist)\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 163, in run_commands\n",
      "      dist.run_commands()\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 967, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 986, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\wheel\\bdist_wheel.py\", line 299, in run\n",
      "      self.run_command('build')\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 986, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-install-2as2bd9y\\jamspell_65f5512d22764ac8a97b2a21f389daae\\setup.py\", line 37, in run\n",
      "      self.run_command('build_ext')\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 986, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 339, in run\n",
      "      self.build_extensions()\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 448, in build_extensions\n",
      "      self._build_extensions_serial()\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 473, in _build_extensions_serial\n",
      "      self.build_extension(ext)\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 506, in build_extension\n",
      "      sources = self.swig_sources(sources, ext)\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 597, in swig_sources\n",
      "      swig = self.swig or self.find_swig()\n",
      "    File \"C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-install-2as2bd9y\\jamspell_65f5512d22764ac8a97b2a21f389daae\\setup.py\", line 49, in find_swig\n",
      "      assert swigBinary is not None\n",
      "  AssertionError\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for jamspell\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\gaura\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2as2bd9y\\\\jamspell_65f5512d22764ac8a97b2a21f389daae\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\gaura\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2as2bd9y\\\\jamspell_65f5512d22764ac8a97b2a21f389daae\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-record-sr63923t\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\Include\\jamspell'\n",
      "         cwd: C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-install-2as2bd9y\\jamspell_65f5512d22764ac8a97b2a21f389daae\\\n",
      "    Complete output (40 lines):\n",
      "    C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\dist.py:732: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "      warnings.warn(\n",
      "    running install\n",
      "    C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "      warnings.warn(\n",
      "    running build_ext\n",
      "    building '_jamspell' extension\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-install-2as2bd9y\\jamspell_65f5512d22764ac8a97b2a21f389daae\\setup.py\", line 55, in <module>\n",
      "        setup(\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\__init__.py\", line 155, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 148, in setup\n",
      "        return run_commands(dist)\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\core.py\", line 163, in run_commands\n",
      "        dist.run_commands()\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 967, in run_commands\n",
      "        self.run_command(cmd)\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 986, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-install-2as2bd9y\\jamspell_65f5512d22764ac8a97b2a21f389daae\\setup.py\", line 43, in run\n",
      "        self.run_command('build_ext')\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 313, in run_command\n",
      "        self.distribution.run_command(command)\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 986, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 339, in run\n",
      "        self.build_extensions()\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 448, in build_extensions\n",
      "        self._build_extensions_serial()\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 473, in _build_extensions_serial\n",
      "        self.build_extension(ext)\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 506, in build_extension\n",
      "        sources = self.swig_sources(sources, ext)\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\setuptools\\_distutils\\command\\build_ext.py\", line 597, in swig_sources\n",
      "        swig = self.swig or self.find_swig()\n",
      "      File \"C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-install-2as2bd9y\\jamspell_65f5512d22764ac8a97b2a21f389daae\\setup.py\", line 49, in find_swig\n",
      "        assert swigBinary is not None\n",
      "    AssertionError\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\gaura\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2as2bd9y\\\\jamspell_65f5512d22764ac8a97b2a21f389daae\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\gaura\\\\AppData\\\\Local\\\\Temp\\\\pip-install-2as2bd9y\\\\jamspell_65f5512d22764ac8a97b2a21f389daae\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\gaura\\AppData\\Local\\Temp\\pip-record-sr63923t\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\Include\\jamspell' Check the logs for full command output.\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ywin32 (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\gaura\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\gaura\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install jamspell\n",
    "!pip install autocorrect\n",
    "!pip install Symspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "txt = 'Hllo'\n",
    "b = TextBlob(txt)\n",
    "print(b.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45899fa507a1304a3c6b832619928507c52e1988c6511a7c9c5f49ebe874162e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
